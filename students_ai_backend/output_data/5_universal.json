{
  "choices": [
    {
      "message": {
        "content": "{\"subsections\":[\"Machine unlearning (MU) is a process to remove the influence of specific data points from a trained model, crucial for compliance with data privacy regulations like GDPR.\",\"Exact unlearning involves retraining the model from scratch, which is computationally expensive, leading to the development of approximate unlearning methods.\",\"Model sparsification through weight pruning can bridge the gap between exact and approximate unlearning, enhancing the performance of approximate unlearning methods.\",\"The study introduces a new paradigm 'prune first, then unlearn', which incorporates model sparsity into the unlearning process, improving efficiency and efficacy.\",\"Experiments demonstrate that model sparsity significantly improves the efficacy of approximate unlearning methods across various scenarios, including defending against backdoor attacks and enhancing transfer learning.\",\"The paper proposes a sparsity-aware unlearning framework that uses sparsity regularization to improve the training process of approximate unlearning methods.\",\"The study highlights the potential of model sparsity to enhance machine unlearning, suggesting future research directions in exploring unlearning patterns within weight or architecture space.\"],\"figures\":[\"Figure 1: Schematic overview of model sparsity-driven MU, showing performance of three unlearning methods under five metrics: unlearning accuracy, MIA-based unlearning efficacy, accuracy on remaining data, testing accuracy, and run-time efficiency.\",\"Figure 2: Testing accuracy of OMP-based sparse ResNet-18 vs. sparsity ratio, showing a graceful sparse regime with lossless testing accuracy.\",\"Figure 3: Performance of approximate unlearning methods and exact unlearning in efficacy, fidelity, and generalization vs. model sparsity in the data-model setup (CIFAR-10, ResNet-18).\",\"Figure 4: Influence of different pruning methods (SynFlow, OMP, and IMP) in unlearning efficacy and generalization on (CIFAR-10, ResNet-18).\",\"Figure 5: Performance of sparsity-aware unlearning vs. FT and Retrain on class-wise forgetting and random data forgetting under (CIFAR-10, ResNet-18).\",\"Figure 6: Performance of Trojan model cleanse via proposed unlearning vs. model sparsity, showing ASR and SA of the Trojan model and its unlearned version.\"],\"equations\":[\"Equation (1): $$\\\\Delta(\\\\mathrm{w}):=\\\\theta(\\\\mathrm{w})-\\\\theta_{\\\\circ}\\\\approx\\\\mathrm{H}^{-1}\\\\nabla_{\\\\theta}L(\\\\mathrm{1}/N-\\\\mathrm{w},\\\\theta_{\\\\circ}),$$\",\"Equation (2): $$e({\\\\bf m})={\\\\cal O}(\\\\eta^{2}t|\\\\ln\\\\bar{\\\\cdot}(\\\\theta_{t}-\\\\theta_{0})||_{2}\\\\sigma({\\\\bf m}))$$\",\"Equation (3): $$\\\\theta_{\\\\mathrm{u}}=\\\\arg_{\\\\mathrm{a}}\\\\operatorname*{min}L_{\\\\mathrm{u}}(\\\\theta;\\\\theta_{\\\\mathrm{o}},D_{\\\\mathrm{r}})+\\\\gamma\\\\|\\\\theta\\\\|_{1},$$\"],\"methods\":[\"Prune first, then unlearn: A paradigm that incorporates model sparsity into the unlearning process to improve efficiency and efficacy.\",\"Sparsity-aware unlearning: A framework that uses sparsity regularization to enhance the training process of approximate unlearning methods.\"],\"metrics\":[\"Unlearning accuracy (UA): Measures the efficacy of MU in the accuracy dimension.\",\"Membership inference attack (MIA)-Efficacy: Assesses the efficacy of unlearning by applying MIA predictor to the unlearned model.\",\"Remaining accuracy (RA): Reflects the fidelity of MU, i.e., training data information preservation.\",\"Testing accuracy (TA): Measures the generalization ability of the unlearned model on a testing dataset.\",\"Run-time efficiency (RTE): Measures the computation efficiency of an MU method.\"],\"words\":[\"scrub\",\"boost\",\"infuse\",\"paradigm\",\"notable highlight\",\"notably\",\"noteworthy\",\"remarkably\",\"promising finding\",\"noteworthy\",\"notably\",\"noteworthy\",\"remarkably\",\"promising finding\"]}",
        "role": "assistant"
      }
    }
  ]
}